{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6fe8a1a",
   "metadata": {},
   "source": [
    "# Power BI Semantic Model Connection (Local)\n",
    "\n",
    "Connect to Power BI Semantic Models from a **local Python environment** using the REST API.\n",
    "\n",
    "## Prerequisites\n",
    "1. **Azure CLI authentication**: Run `az login` before starting\n",
    "2. **Power BI Premium, PPU, or Fabric capacity**: Required for executing DAX queries\n",
    "3. **Workspace access**: You need at least read access to the workspace and semantic model\n",
    "\n",
    "> **Note**: The `semantic-link` library's XMLA-based functions (`read_table`, `list_tables`) only work inside Fabric notebooks. This notebook uses the REST API which works locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2160c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from azure.identity import DefaultAzureCredential, DeviceCodeCredential\n",
    "from azure.core.exceptions import ClientAuthenticationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate to Power BI\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    token = credential.get_token(\"https://analysis.windows.net/powerbi/api/.default\")\n",
    "    print(\"✓ Authenticated using DefaultAzureCredential\")\n",
    "except ClientAuthenticationError:\n",
    "    print(\"DefaultAzureCredential failed. Using DeviceCodeCredential...\")\n",
    "    credential = DeviceCodeCredential()\n",
    "    token = credential.get_token(\"https://analysis.windows.net/powerbi/api/.default\")\n",
    "    print(\"✓ Authenticated using DeviceCodeCredential\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d4986",
   "metadata": {},
   "source": [
    "## Power BI REST API Helper Class\n",
    "\n",
    "A reusable class for interacting with Power BI semantic models from local Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ec6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerBIClient:\n",
    "    \"\"\"Client for interacting with Power BI semantic models via REST API.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.powerbi.com/v1.0/myorg\"\n",
    "    \n",
    "    def __init__(self, credential):\n",
    "        self.credential = credential\n",
    "        self._workspaces_cache = None\n",
    "    \n",
    "    def _get_headers(self):\n",
    "        token = self.credential.get_token(\"https://analysis.windows.net/powerbi/api/.default\")\n",
    "        return {\n",
    "            \"Authorization\": f\"Bearer {token.token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "    def list_workspaces(self) -> pd.DataFrame:\n",
    "        \"\"\"List all workspaces the user has access to.\"\"\"\n",
    "        response = requests.get(f\"{self.BASE_URL}/groups\", headers=self._get_headers())\n",
    "        response.raise_for_status()\n",
    "        workspaces = response.json().get(\"value\", [])\n",
    "        self._workspaces_cache = {ws[\"name\"]: ws for ws in workspaces}\n",
    "        return pd.DataFrame(workspaces)\n",
    "    \n",
    "    def get_workspace_id(self, workspace_name: str) -> str:\n",
    "        \"\"\"Get workspace ID by name.\"\"\"\n",
    "        if not self._workspaces_cache:\n",
    "            self.list_workspaces()\n",
    "        ws = self._workspaces_cache.get(workspace_name)\n",
    "        if not ws:\n",
    "            raise ValueError(f\"Workspace '{workspace_name}' not found\")\n",
    "        return ws[\"id\"]\n",
    "    \n",
    "    def is_premium(self, workspace_name: str) -> bool:\n",
    "        \"\"\"Check if workspace is on Premium/Fabric capacity.\"\"\"\n",
    "        if not self._workspaces_cache:\n",
    "            self.list_workspaces()\n",
    "        ws = self._workspaces_cache.get(workspace_name)\n",
    "        return ws.get(\"isOnDedicatedCapacity\", False) if ws else False\n",
    "    \n",
    "    def list_datasets(self, workspace_name: str) -> pd.DataFrame:\n",
    "        \"\"\"List all datasets in a workspace.\"\"\"\n",
    "        workspace_id = self.get_workspace_id(workspace_name)\n",
    "        url = f\"{self.BASE_URL}/groups/{workspace_id}/datasets\"\n",
    "        response = requests.get(url, headers=self._get_headers())\n",
    "        response.raise_for_status()\n",
    "        return pd.DataFrame(response.json().get(\"value\", []))\n",
    "    \n",
    "    def get_dataset_id(self, workspace_name: str, dataset_name: str) -> str:\n",
    "        \"\"\"Get dataset ID by name.\"\"\"\n",
    "        df = self.list_datasets(workspace_name)\n",
    "        match = df[df[\"name\"] == dataset_name]\n",
    "        if match.empty:\n",
    "            raise ValueError(f\"Dataset '{dataset_name}' not found in workspace '{workspace_name}'\")\n",
    "        return match.iloc[0][\"id\"]\n",
    "    \n",
    "    def execute_dax(self, workspace_name: str, dataset_name: str, dax_query: str) -> pd.DataFrame:\n",
    "        \"\"\"Execute a DAX query and return results as DataFrame.\"\"\"\n",
    "        workspace_id = self.get_workspace_id(workspace_name)\n",
    "        dataset_id = self.get_dataset_id(workspace_name, dataset_name)\n",
    "        \n",
    "        url = f\"{self.BASE_URL}/groups/{workspace_id}/datasets/{dataset_id}/executeQueries\"\n",
    "        payload = {\n",
    "            \"queries\": [{\"query\": dax_query}],\n",
    "            \"serializerSettings\": {\"includeNulls\": True}\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self._get_headers(), json=payload)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            error = response.json().get(\"error\", {})\n",
    "            raise RuntimeError(f\"DAX query failed: {error.get('message', response.text)}\")\n",
    "        \n",
    "        result = response.json()\n",
    "        tables = result.get(\"results\", [{}])[0].get(\"tables\", [])\n",
    "        if tables:\n",
    "            rows = tables[0].get(\"rows\", [])\n",
    "            return pd.DataFrame(rows)\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    def read_table(self, workspace_name: str, dataset_name: str, table_name: str, \n",
    "                   top_n: int = None, columns: list = None) -> pd.DataFrame:\n",
    "        \"\"\"Read data from a table in a semantic model.\"\"\"\n",
    "        col_list = \", \".join(columns) if columns else \"*\"\n",
    "        \n",
    "        if top_n:\n",
    "            dax = f\"EVALUATE TOPN({top_n}, '{table_name}')\"\n",
    "        else:\n",
    "            dax = f\"EVALUATE '{table_name}'\"\n",
    "        \n",
    "        return self.execute_dax(workspace_name, dataset_name, dax)\n",
    "    \n",
    "    def evaluate_measure(self, workspace_name: str, dataset_name: str, \n",
    "                         measure: str, group_by: list = None) -> pd.DataFrame:\n",
    "        \"\"\"Evaluate a measure, optionally grouped by columns.\"\"\"\n",
    "        if group_by:\n",
    "            cols = \", \".join(group_by)\n",
    "            dax = f\"\"\"\n",
    "            EVALUATE \n",
    "            SUMMARIZECOLUMNS(\n",
    "                {cols},\n",
    "                \"Result\", {measure}\n",
    "            )\n",
    "            \"\"\"\n",
    "        else:\n",
    "            dax = f\"EVALUATE ROW(\\\"Result\\\", {measure})\"\n",
    "        \n",
    "        return self.execute_dax(workspace_name, dataset_name, dax)\n",
    "\n",
    "# Initialize the client\n",
    "pbi = PowerBIClient(credential)\n",
    "print(\"✓ PowerBIClient initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d7cd7",
   "metadata": {},
   "source": [
    "## 1. List Workspaces and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9627535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List workspaces\n",
    "df_workspaces = pbi.list_workspaces()\n",
    "print(f\"Found {len(df_workspaces)} workspaces\")\n",
    "display(df_workspaces[[\"name\", \"id\", \"isOnDedicatedCapacity\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - set your workspace and dataset names\n",
    "WORKSPACE_NAME = \"perry-pbi-demo-workspace\"\n",
    "DATASET_NAME = \"Customer Profitability Sample\"\n",
    "\n",
    "# Check if workspace is on Premium capacity\n",
    "if pbi.is_premium(WORKSPACE_NAME):\n",
    "    print(f\"✓ Workspace '{WORKSPACE_NAME}' is on Premium/Fabric capacity\")\n",
    "else:\n",
    "    print(f\"✗ Workspace '{WORKSPACE_NAME}' is NOT on Premium capacity - DAX queries will fail!\")\n",
    "\n",
    "# List datasets in workspace\n",
    "df_datasets = pbi.list_datasets(WORKSPACE_NAME)\n",
    "print(f\"\\nDatasets in '{WORKSPACE_NAME}':\")\n",
    "display(df_datasets[[\"name\", \"id\", \"configuredBy\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec36cc19",
   "metadata": {},
   "source": [
    "## 2. Read Data from a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f87c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first 10 rows from the 'Customer' table\n",
    "df_customers = pbi.read_table(WORKSPACE_NAME, DATASET_NAME, \"Customer\", top_n=10)\n",
    "print(f\"Retrieved {len(df_customers)} rows from 'Customer' table\")\n",
    "display(df_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3281a2e5",
   "metadata": {},
   "source": [
    "## 3. Execute Custom DAX Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5816fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a custom DAX query\n",
    "dax_query = \"\"\"\n",
    "EVALUATE\n",
    "SUMMARIZECOLUMNS(\n",
    "    'Customer'[State],\n",
    "    \"Customer Count\", COUNTROWS('Customer')\n",
    ")\n",
    "ORDER BY [Customer Count] DESC\n",
    "\"\"\"\n",
    "\n",
    "df_result = pbi.execute_dax(WORKSPACE_NAME, DATASET_NAME, dax_query)\n",
    "print(f\"Query returned {len(df_result)} rows\")\n",
    "display(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3061ec12",
   "metadata": {},
   "source": [
    "## 4. Evaluate a Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a measure (replace with an actual measure from your model)\n",
    "# Example: Evaluate [Total Revenue] grouped by State\n",
    "try:\n",
    "    df_measure = pbi.evaluate_measure(\n",
    "        WORKSPACE_NAME, \n",
    "        DATASET_NAME, \n",
    "        \"[Total Revenue]\",  # Replace with your measure name\n",
    "        group_by=[\"'Customer'[State]\"]\n",
    "    )\n",
    "    display(df_measure.head(10))\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")\n",
    "    print(\"Tip: Replace '[Total Revenue]' with an actual measure from your semantic model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
